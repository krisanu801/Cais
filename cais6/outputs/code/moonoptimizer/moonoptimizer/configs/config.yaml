dataset:
  n_samples: 1000
  noise: 0.2
  test_size: 0.2

model:
  hidden_size: 64

training:
  batch_size: 32
  epochs: 100

optimizer:
  darms:
    learning_rate: 0.001
    beta1: 0.9
    beta2: 0.999
  adamw:
    learning_rate: 0.001

weight_decay: 0.0001